# Neural networks

# Task 0: Neural networks mat lab
A neural network is called a Shallow network when the network has lower number of hidden layers
ranging as 1 or 2.
To learn shallow networks mat lab Neural fitting (nftool) is used.This tool helps in training basic
preloaded datasets and along with those datasets external set can also be used.
This GUI provides three kinds of training algorithms.
• Bayesian Regularization :
This algorithm takes up more time compared to others but results are worth the wait nd Training
stops according to adaptive weight minimization (regularization).
• Scaled Conjugate Gradient :
This algorithm occupies less memory and automatically stops when generalization stops improving.
• Levenberg-Marquardt :
This algorithm consumes more memory but takes less time to train and automatically stops when
generalization stops improving.
This task preloaded sets are used and obtained results are compared and observations are as follows.
When the data set size is less the outliers are close to zero but with increase in size of dataset the outlier
increases regardless the algorithm but if the network is retrained according to needs the outliers can be
avoided.The difference between less training and more training is shown below as well as the difference is
same in terms of lower amount of data.

# Task 1: Feed forward multi-layer networks
The Mat-lab provides a tool called nprtool which helps in learning Neural pattern recognition.This
GUI, works similar to nftool, consists of preloaded datasets and external datasets can also be used.
